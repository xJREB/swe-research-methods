@incollection{Ciolkowski2003,
abstract = {A survey is an empirical research strategy for the collection of information from heterogeneous sources. In this way, survey results often exhibit a high degree of external validity. It is complementary to other empirical research strategies such as controlled experiments, which usually have their strengths in the high internal validity of the findings. While there is a growing number of (quasi-)controlled experiments reported in the software engineering literature, few results of large scale surveys have been reported there. Hence, there is still a lack of knowledge on how to use surveys in a systematic manner for software engineering empirical research. This chapter introduces a process for preparing, conducting, and analyzing a software engineering survey. The focus of the work is on questionnaire-based surveys rather than literature surveys. The survey process is driven by practical experiences from two large-scale efforts in the review and inspection area. There are two main results from this work. First, the process itself allows researchers in empirical software engineering to follow a systematic, disciplined approach. Second, the experiences from applying the process help avoid common pitfalls that endanger both the research process and its results. We report on two (descriptive) surveys on software reviews that applied the survey process, and we present our experiences, as well as models for survey effort and duration factors derived from these experiences. {\textcopyright} Springer-Verlag Berlin Heidelberg 2003.},
author = {Ciolkowski, Marcus and Laitenberger, Oliver and Vegas, Sira and Biffl, Stefan},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-45143-3_7},
isbn = {978-3-540-45143-3},
mendeley-groups = {07 Surveys},
pages = {104--128},
publisher = {Springer Berlin Heidelberg},
title = {{Practical Experiences in the Design and Conduct of Surveys in Empirical Software Engineering}},
url = {http://link.springer.com/10.1007/978-3-540-45143-3{\_}7},
volume = {2765},
year = {2003}
}
@techreport{Kasunic2005,
abstract = {A survey can characterize the knowledge, attitudes, and behaviors of a large group of people through the study of a subset of them. However, to protect the validity of conclusions drawn from a survey, certain procedures must be followed throughout the process of designing, developing, and distributing the survey questionnaire. Surveys are used extensively by software and systems engineering organizations to provide insight into complex issues, assist with problem solving, and support effective decision making. This document presents a seven-stage, end-to-end process for conducting a survey.},
address = {Pittsburgh, PA},
author = {Kasunic, Mark},
institution = {Carnegie Mellon University, Software Engineering Institute},
isbn = {0780348907},
mendeley-groups = {07 Surveys},
pages = {143},
title = {{Designing an Effective Survey}},
url = {http://www.sei.cmu.edu/reports/05hb004.pdf},
year = {2005}
}
@incollection{Kitchenham2008,
address = {London},
author = {Kitchenham, Barbara A. and Pfleeger, Shari L.},
booktitle = {Guide to Advanced Empirical Software Engineering},
doi = {10.1007/978-1-84800-044-5_3},
mendeley-groups = {07 Surveys},
pages = {63--92},
publisher = {Springer London},
title = {{Personal Opinion Surveys}},
url = {http://link.springer.com/10.1007/978-1-84800-044-5{\_}3},
year = {2008}
}
@inproceedings{Molleri2016,
abstract = {Background: Survey is a method of research aiming to gather data from a large population of interest. Despite being extensively used in software engineering, survey-based research faces several challenges, such as selecting a representative population sample and designing the data collection instruments. Objective: This article aims to summarize the existing guidelines, supporting instruments and recommendations on how to conduct and evaluate survey-based research. Methods: A systematic search using manual search and snowballing techniques were used to identify primary studies supporting survey research in software engineering. We used an annotated review to present the findings, describing the references of interest in the research topic. Results: The summary provides a description of 15 available articles addressing the survey methodology, based upon which we derived a set of recommendations on how to conduct survey research, and their impact in the community. Conclusion: Survey-based research in software engineering has its particular challenges, as illustrated by several articles in this review. The annotated review can contribute by raising awareness of such challenges and present the proper recommendations to overcome them.},
address = {New York, New York, USA},
author = {Molleri, Jefferson Seide and Petersen, Kai and Mendes, Emilia},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement - ESEM '16},
doi = {10.1145/2961111.2962619},
isbn = {9781450344272},
issn = {19493789},
mendeley-groups = {07 Surveys},
pages = {1--6},
publisher = {ACM Press},
title = {{Survey Guidelines in Software Engineering}},
url = {http://dl.acm.org/citation.cfm?doid=2961111.2962619},
volume = {08-09-Sept},
year = {2016}
}
@article{Molleri2020a,
abstract = {Context: Over the past decade Software Engineering research has seen a steady increase in survey-based studies, and there are several guidelines providing support for those willing to carry out surveys. The need for auditing survey research has been raised in the literature. Checklists have been used both to conduct and to assess different types of empirical studies, such as experiments and case studies. Objective: To operationalize the assessment of survey studies by means of a checklist. To fulfill such goal, we aim to derive a checklist from standards for survey research and further evaluate the appropriateness of the checklist in the context of software engineering research. Method: We systematically aggregated knowledge from 12 methodological studies supporting survey-based research in software engineering. We identified the key stages of the survey process and its recommended practices through thematic analysis and vote counting. We evaluated the checklist by applying it to existing surveys and analyzed the results. Thereafter, we gathered the feedback of experts (the surveys' authors) on our analysis and used the feedback to improve the survey checklist. Results: The evaluation provided insights regarding limitations of the checklist in relation to its understanding and objectivity. In particular, 19 of the 38 checklist items were improved according to the feedback received from experts. Conclusion: The proposed checklist is appropriate for auditing survey reports as well as a support tool to guide ongoing research with regard to the survey design process. A discussion on how to use the checklist and what its implications are for research practice is also provided.},
author = {Moll{\'{e}}ri, Jefferson Seide and Petersen, Kai and Mendes, Emilia},
doi = {10.1016/j.infsof.2019.106240},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Assessment,Checklist,Methodology,Survey},
mendeley-groups = {07 Surveys},
month = {mar},
pages = {106240},
title = {{An empirically evaluated checklist for surveys in software engineering}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584919302575},
volume = {119},
year = {2020}
}
@article{Molleri2020,
abstract = {Context: Over the past decade Software Engineering research has seen a steady increase in survey-based studies, and there are several guidelines providing support for those willing to carry out surveys. The need for auditing survey research has been raised in the literature. Checklists have been used both to conduct and to assess different types of empirical studies, such as experiments and case studies. Objective: To operationalize the assessment of survey studies by means of a checklist. To fulfill such goal, we aim to derive a checklist from standards for survey research and further evaluate the appropriateness of the checklist in the context of software engineering research. Method: We systematically aggregated knowledge from 12 methodological studies supporting survey-based research in software engineering. We identified the key stages of the survey process and its recommended practices through thematic analysis and vote counting. We evaluated the checklist by applying it to existing surveys and analyzed the results. Thereafter, we gathered the feedback of experts (the surveys' authors) on our analysis and used the feedback to improve the survey checklist. Results: The evaluation provided insights regarding limitations of the checklist in relation to its understanding and objectivity. In particular, 19 of the 38 checklist items were improved according to the feedback received from experts. Conclusion: The proposed checklist is appropriate for auditing survey reports as well as a support tool to guide ongoing research with regard to the survey design process. A discussion on how to use the checklist and what its implications are for research practice is also provided.},
author = {Moll{\'{e}}ri, Jefferson Seide and Petersen, Kai and Mendes, Emilia},
doi = {10.1016/j.infsof.2019.106240},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Assessment,Checklist,Methodology,Survey},
mendeley-groups = {07 Surveys},
month = {mar},
pages = {106240},
title = {{An empirically evaluated checklist for surveys in software engineering}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584919302575},
volume = {119},
year = {2020}
}
@incollection{Wagner2020,
abstract = {While being an important and often used research method, survey research has been less often discussed on a methodological level in empirical software engineering than other types of research. This chapter compiles a set of important and challenging issues in survey research based on experiences with several large-scale international surveys. The chapter covers theory building, sampling, invitation and follow-up, statistical as well as qualitative analysis of survey data and the usage of psychometrics in software engineering surveys.},
address = {Cham},
author = {Wagner, Stefan and Mendez, Daniel and Felderer, Michael and Graziotin, Daniel and Kalinowski, Marcos},
booktitle = {Contemporary Empirical Methods in Software Engineering},
doi = {10.1007/978-3-030-32489-6_4},
isbn = {9783030324896},
mendeley-groups = {07 Surveys},
pages = {93--125},
publisher = {Springer International Publishing},
title = {{Challenges in Survey Research}},
url = {http://link.springer.com/10.1007/978-3-030-32489-6{\_}4},
year = {2020}
}
